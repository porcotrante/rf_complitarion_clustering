import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import argparse
import os
import numpy as np
import math

# Define consistent colors and markers for strategies
STRATEGY_AESTHETICS = {
    'ES': {'color': 'blue', 'marker': 'o', 'linestyle': '-'},
    'AbsES': {'color': 'green', 'marker': 's', 'linestyle': '--'},
    'HEUR': {'color': 'red', 'marker': '^', 'linestyle': ':'},
    'ORD': {'color': 'purple', 'marker': 'D', 'linestyle': '-.'}
}

"""
Python script to visualize benchmark results from the CSV generated by compile-rf.
Generates three plots:
1. Faceted by k: Stacked bars comparing strategies within each k.
2. Faceted by Strategy: Stacked bars comparing k values within each strategy.
3. Grouped Stacked Bars: Single plot comparing k-scaling across strategies.
"""

# --- Function: plot_faceted_by_k ---
def plot_faceted_by_k(df_agg, dataset_name, output_dir):
    """Generates the plot faceted by k value, using aggregated data. Shows Mean Min Wall Time."""
    unique_k_values = sorted(df_agg['k'].unique())
    n_k_values = len(unique_k_values)
    metric_col = 'TotalTime_Min_mean'

    # --- Plotting Setup ---
    plt.style.use('seaborn-v0_8-whitegrid')
    n_cols = math.ceil(math.sqrt(n_k_values))
    n_rows = math.ceil(n_k_values / n_cols)
    fig, axes = plt.subplots(n_rows, n_cols, figsize=(6 * n_cols, 5 * n_rows), sharey=True, squeeze=False)
    axes_flat = axes.flatten()
    max_y_value = 0

    # --- Iterate through each k value and create subplot ---
    for i, k_value in enumerate(unique_k_values):
        ax = axes_flat[i]
        # Use the aggregated dataframe filtered by k
        df_k_agg = df_agg[df_agg['k'] == k_value].copy()

        # --- Data Preparation for Simple Bar ---
        # Set Strategy as index for plotting
        df_plot = df_k_agg.set_index('Strategy')

        # Create simple bar plot for the specified metric
        df_plot[metric_col].plot(kind='bar', ax=ax, color=[STRATEGY_AESTHETICS.get(s, {'color': 'gray'})['color'] for s in df_plot.index], legend=False)

        ax.set_title(f'k = {k_value}', fontsize=14)
        ax.set_xlabel('')
        ax.tick_params(axis='x', rotation=0)

        # Add total time labels (which is the bar height)
        totals = df_plot[metric_col]

        current_max_y = totals.max() * 1.05
        max_y_value = max(max_y_value, current_max_y if pd.notna(current_max_y) else 0)

    # --- Figure-level Adjustments ---
    fig.text(0.01, 0.5, 'Mean Min Wall Time (seconds)', va='center', rotation='vertical', fontsize=12)
    fig.text(0.5, 0.01, 'Early Stopping Strategy', ha='center', fontsize=12)

    for j in range(i + 1, len(axes_flat)):
        axes_flat[j].set_visible(False)
    for ax in axes_flat:
        ax.set_ylim(0, max_y_value)
    fig.suptitle(f'Mean Min Wall Time Comparison (Faceted by k, Dataset: {dataset_name})', fontsize=18, y=0.99)
    plt.tight_layout(rect=[0.03, 0.03, 0.97, 0.95])

    # Save the plot
    plot_filename = os.path.join(output_dir, f'benchmark_faceted_k_plot_{dataset_name}.svg')
    plt.savefig(plot_filename)
    print(f"Plot faceted by k saved as '{plot_filename}'")
    plt.close(fig) # Close the figure to free memory

# --- Function: plot_faceted_by_strategy ---
def plot_faceted_by_strategy(df_agg, dataset_name, output_dir):
    """Generates the plot faceted by strategy, using aggregated data. Shows Mean Min Wall Time."""
    unique_strategies = df_agg['Strategy'].unique()
    n_strategies = len(unique_strategies)
    metric_col = 'TotalTime_Min_mean' # Metric to plot

    # --- Plotting Setup ---
    plt.style.use('seaborn-v0_8-whitegrid')
    n_cols = math.ceil(math.sqrt(n_strategies))
    n_rows = math.ceil(n_strategies / n_cols)

    fig, axes = plt.subplots(n_rows, n_cols, figsize=(6 * n_cols, 5 * n_rows), sharey=True, squeeze=False)
    axes_flat = axes.flatten()
    max_y_value = 0

    # --- Iterate through each strategy and create subplot ---
    for i, strategy in enumerate(unique_strategies):
        ax = axes_flat[i]
        # Use the aggregated dataframe filtered by strategy
        df_strat_agg = df_agg[df_agg['Strategy'] == strategy].copy()

        # --- Data Preparation for Simple Bar ---
        df_plot = df_strat_agg.set_index('k')

        # Create simple bar plot for the specified metric
        df_plot[metric_col].plot(kind='bar', ax=ax, color='skyblue', legend=False)

        ax.set_title(f'Strategy = {strategy}', fontsize=14)
        ax.set_xlabel('') # Remove individual x-labels
        ax.tick_params(axis='x', rotation=0) # Keep k values horizontal

        # Add total time labels (which is the bar height)
        totals = df_plot[metric_col]

        current_max_y = totals.max() * 1.05
        max_y_value = max(max_y_value, current_max_y if pd.notna(current_max_y) else 0)

    # --- Figure-level Adjustments ---
    fig.text(0.01, 0.5, 'Mean Min Wall Time (seconds)', va='center', rotation='vertical', fontsize=12)
    fig.text(0.5, 0.01, 'Partitioning Level (k)', ha='center', fontsize=12)

    for j in range(i + 1, len(axes_flat)):
        axes_flat[j].set_visible(False)
    for ax in axes_flat:
        ax.set_ylim(0, max_y_value)
    fig.suptitle(f'Mean Min Wall Time Comparison (Faceted by Strategy, Dataset: {dataset_name})', fontsize=18, y=0.99)
    plt.tight_layout(rect=[0.03, 0.03, 0.97, 0.95])

    # Save the plot
    plot_filename = os.path.join(output_dir, f'benchmark_faceted_strategy_plot_{dataset_name}.svg')
    plt.savefig(plot_filename)
    print(f"Plot faceted by strategy saved as '{plot_filename}'")
    plt.close(fig) # Close the figure

def plot_grouped_bars(df_agg, dataset_name, output_dir):
    """Generates a single plot with grouped bars (Strategies on x-axis, groups for k), showing Mean Min Wall Time."""
    metric_col = 'TotalTime_Min_mean'
    unique_strategies = df_agg['Strategy'].unique()
    unique_k_values = sorted(df_agg['k'].unique())
    n_strategies = len(unique_strategies)
    n_k_values = len(unique_k_values)

    # --- Data Preparation ---
    # Pivot table to get Strategies as index, k as columns, and the metric as values
    df_pivot = df_agg.pivot(index='Strategy', columns='k', values=metric_col)

    # --- Plotting Setup ---
    plt.style.use('seaborn-v0_8-whitegrid')
    fig, ax = plt.subplots(figsize=(max(8, n_strategies * n_k_values * 0.3), 7)) # Adjust width based on bars

    # --- Grouped Bar Plot ---
    df_pivot.plot(kind='bar', ax=ax, colormap='viridis', width=0.8)

    # --- Final Plot Adjustments ---
    ax.set_title(f'Mean Min Wall Time Comparison (Grouped by k) (Dataset: {dataset_name})', fontsize=16) 
    ax.set_ylabel('Mean Min Wall Time (seconds)', fontsize=12)
    ax.set_xlabel('Early Stopping Strategy', fontsize=12)
    ax.tick_params(axis='x', rotation=0)
    ax.legend(title='k Value')
    plt.tight_layout()

    # Add value labels above bars
    max_y_value = df_pivot.max().max() * 1.1 # Find max for label positioning
    ax.set_ylim(0, max_y_value)

    # Save the plot
    plot_filename = os.path.join(output_dir, f'benchmark_grouped_bar_plot_{dataset_name}.svg') # New filename
    plt.savefig(plot_filename)
    print(f"Grouped bar plot saved as '{plot_filename}'")
    plt.close(fig)


def aggregate_results(df):
    """Aggregates results across seeds, calculating mean and std dev."""

    # Define the metrics to aggregate and how
    agg_funcs = {
        # Aggregate the 'Min' times calculated by Rust for each seed
        'TotalTime_Min': ['mean', 'std'],
        'CpuTime_Min': ['mean', 'std'],

        # Aggregate the 'Mean' component times across seeds for stacked plots
        'AssemblyTime_Min': ['mean', 'std'],
        'PartitionProcessingTime_Min': ['mean', 'std'],
        'OtherTime_Min': ['mean', 'std'],

        # Aggregate other metrics directly
        'Nodes': ['mean', 'std'],
        'Height': ['mean', 'std'],
        'Mismatches': ['mean', 'std'],
    }

    # --- Accuracy aggregation ---
    if 'accuracy' in df.columns:
        agg_funcs['accuracy'] = ['mean']

    # Add conditional aggregation for pruning counts if they exist
    if 'SimplifyPruningCount' in df.columns:
        agg_funcs['SimplifyPruningCount'] = ['mean', 'std']
    if 'MergePruningCount' in df.columns:
        agg_funcs['MergePruningCount'] = ['mean', 'std']

    # Group by k and Strategy, then aggregate across seeds
    aggregated_df = df.groupby(['k', 'Strategy']).agg(agg_funcs)

    # Flatten the multi-index columns
    aggregated_df.columns = ['_'.join(col).strip() for col in aggregated_df.columns.values]

    # Reset index to make 'k' and 'Strategy' regular columns
    aggregated_df = aggregated_df.reset_index()

    # Handle cases where std dev is NaN (e.g., only one seed was run)
    for col in aggregated_df.columns:
        if col.endswith('_std'):
            aggregated_df[col] = aggregated_df[col].fillna(0)

    # --- Rename accuracy column to meanAccuracy ---
    if 'accuracy_mean' in aggregated_df.columns:
        aggregated_df = aggregated_df.rename(
            columns={'accuracy_mean': 'meanAccuracy'}
        )

    print("Aggregated DataFrame Head:")
    print(aggregated_df.head())

    return aggregated_df

def plot_metric_vs_k(agg_df, metric_mean_col, metric_std_col, y_label, title, output_filename_base, use_log_scale=False):
    """
    Plots an aggregated metric (mean +/- std dev) vs. k for different strategies,
    with dodging and optional log scale.
    """
    plt.figure(figsize=(6, 3))

    strategies = sorted(agg_df['Strategy'].unique()) # Sort for consistent offset order
    n_strategies = len(strategies)
    # Define total width to spread points for one k, and calculate width per strategy
    total_width = 0.8
    width_per_strategy = total_width / n_strategies

    for i, strategy in enumerate(strategies):
        strategy_df = agg_df[agg_df['Strategy'] == strategy].sort_values('k')
        aesthetics = STRATEGY_AESTHETICS.get(strategy, {'color': 'black', 'marker': '.', 'linestyle': '-'}) # Default fallback
        offset = 0

        # Filter out zero/negative values for log scale if necessary (though unlikely for time/nodes)
        plot_data = strategy_df.copy()
        if use_log_scale:
            plot_data = plot_data[plot_data[metric_mean_col] > 0]
            yerr = plot_data[metric_std_col]
        else:
            yerr = plot_data[metric_std_col]


        plt.errorbar(
            plot_data['k'] + offset, # Apply offset to x-coordinate
            plot_data[metric_mean_col],
            yerr=yerr,
            label=strategy,
            fmt=aesthetics['marker'],
            linestyle=aesthetics['linestyle'],
            color=aesthetics['color'],
            capsize=5, # Add caps to error bars
            alpha=0.7
        )

    # Adjust labels and filename for log scale
    final_y_label = y_label
    final_title = title
    final_output_filename = output_filename_base
    if use_log_scale:
        plt.yscale('log')
        final_y_label = f"{y_label} (Log Scale)"
        final_title = f"{title} (Log Scale)"
        # Insert _log before the extension
        base, ext = os.path.splitext(output_filename_base)
        final_output_filename = f"{base}_log{ext}"


    plt.xlabel("Partitioning Depth (k)")
    plt.ylabel(final_y_label)
    plt.legend(title="Strategy")
    plt.grid(True, which='both', linestyle='--', linewidth=0.5)
    # Ensure ticks are at the original integer k values, not the offset positions
    plt.xticks(sorted(agg_df['k'].unique()))

    if not use_log_scale:
        plt.ylim(bottom=0)

    plt.tight_layout()
    plt.savefig(final_output_filename)
    print(f"Saved plot: {final_output_filename}")
    plt.close()

def visualize_results(csv_path, dataset_name, base_output_dir):
    """
    Reads benchmark data from CSV, aggregates across seeds, and generates comparative plots.
    Saves plots into a subdirectory named after the dataset.

    Args:
        csv_path (str): Path to the benchmark results CSV file.
        dataset_name (str): Name of the dataset (used for plot title and filename).
        base_output_dir (str): Base directory where the dataset-specific subdirectory will be created.
    """
    if not os.path.exists(csv_path):
        print(f"Error: CSV file not found at '{csv_path}'")
        return

    try:
        df = pd.read_csv(csv_path)
    except Exception as e:
        print(f"Error reading CSV file: {e}")
        return

    if df.empty:
        print("Error: CSV file is empty or contains no data.")
        return

    # --- Create dataset-specific output directory ---
    output_dir = os.path.join(base_output_dir, dataset_name)
    os.makedirs(output_dir, exist_ok=True)
    print(f"Saving plots to: {output_dir}")


    # --- Aggregate results across seeds FIRST ---
    agg_df = aggregate_results(df.copy()) # Use copy to avoid modifying original df if needed later

    # Check if 'TotalTime_Min_mean' exists after aggregation (still needed for the new plots)
    if 'TotalTime_Min_mean' not in agg_df.columns:
        print("Error: 'TotalTime_Min_mean' column not found after aggregation. Check CSV and aggregation logic.")
        return

    # --- Define the desired strategy order ---
    strategy_order = ['ES', 'AbsES', 'HEUR', 'ORD']

    # --- Convert 'Strategy' column to Categorical with the specified order IN AGGREGATED DF ---
    present_strategies = agg_df['Strategy'].unique()
    ordered_present_strategies = [s for s in strategy_order if s in present_strategies]
    if not ordered_present_strategies:
        print("Error: None of the specified strategies found in the 'Strategy' column of aggregated data.")
        return
    agg_df['Strategy'] = pd.Categorical(agg_df['Strategy'], categories=ordered_present_strategies, ordered=True)

    # Ensure k is treated correctly (sort for consistent plot order)
    agg_df['k'] = agg_df['k'].astype(int)
    # Sorting is handled within plotting functions or before calling them as needed

    # Ensure output directory exists
    os.makedirs(output_dir, exist_ok=True)

    # --- Generate Plot Faceted by k (using aggregated data) ---
    agg_df_sorted_k = agg_df.sort_values(by=['k', 'Strategy'])
    plot_faceted_by_k(agg_df_sorted_k.copy(), dataset_name, output_dir)

    # --- Generate Plot Faceted by Strategy (using aggregated data) ---
    agg_df_sorted_strategy = agg_df.sort_values(by=['Strategy', 'k'])
    plot_faceted_by_strategy(agg_df_sorted_strategy.copy(), dataset_name, output_dir) 

    # --- Generate Grouped Bar Plot (using aggregated data) ---
    plot_grouped_bars(agg_df_sorted_strategy.copy(), dataset_name, output_dir)

    # --- Plotting Aggregated Metrics (Mean +/- Std Dev) ---
    # 1. Plot Mean Wall Time (Min per Seed) vs. k (Linear and Log)
    wall_time_filename_base = os.path.join(output_dir, f"{dataset_name}_wall_time_vs_k_agg_seeds.svg")
    plot_metric_vs_k(
        agg_df,
        metric_mean_col='TotalTime_Min_mean',
        metric_std_col='TotalTime_Min_std',
        y_label="Mean wall time (s)",
        title=f"{dataset_name.capitalize()}: mean +/- std [among 10 trees] of min wall time [among 3 runs]",
        output_filename_base=wall_time_filename_base,
        use_log_scale=False # Linear scale
    )
    plot_metric_vs_k(
        agg_df,
        metric_mean_col='TotalTime_Min_mean',
        metric_std_col='TotalTime_Min_std',
        y_label="Mean wall time (s)",
        title=f"{dataset_name.capitalize()}: mean +/- std (among 10 trees) of min wall time (s) [among 3 runs]",
        output_filename_base=wall_time_filename_base,
        use_log_scale=True
    )


    # 2. Plot Mean CPU Time (Min per Seed) vs. k (Linear and Log)
    cpu_time_filename_base = os.path.join(output_dir, f"{dataset_name}_cpu_time_vs_k_agg_seeds.svg")
    plot_metric_vs_k(
        agg_df,
        metric_mean_col='CpuTime_Min_mean',
        metric_std_col='CpuTime_Min_std',
        y_label="Mean CPU Time (s) (Min per Seed)",
        title=f"{dataset_name.capitalize()}: Mean Transformation CPU Time vs. k",
        output_filename_base=cpu_time_filename_base,
        use_log_scale=False # Linear scale
    )
    plot_metric_vs_k(
        agg_df,
        metric_mean_col='CpuTime_Min_mean',
        metric_std_col='CpuTime_Min_std',
        y_label="Mean CPU Time (s) (Min per Seed)",
        title=f"{dataset_name.capitalize()}: Mean Transformation CPU Time vs. k",
        output_filename_base=cpu_time_filename_base,
        use_log_scale=True
    )

    # 3. Plot Mean Merged Tree Nodes vs. k (Linear and Log)
    nodes_filename_base = os.path.join(output_dir, f"{dataset_name}_nodes_vs_k_agg_seeds.svg")
    plot_metric_vs_k(
        agg_df,
        metric_mean_col='Nodes_mean',
        metric_std_col='Nodes_std',
        y_label="Mean Merged Tree Nodes",
        title=f"{dataset_name.capitalize()}: Mean Merged Tree Nodes vs. k",
        output_filename_base=nodes_filename_base,
        use_log_scale=False # Linear scale
    )
    plot_metric_vs_k(
        agg_df,
        metric_mean_col='Nodes_mean',
        metric_std_col='Nodes_std',
        y_label="Mean Merged Tree Nodes",
        title=f"{dataset_name.capitalize()}: Mean Merged Tree Nodes vs. k",
        output_filename_base=nodes_filename_base,
        use_log_scale=True
    )

    # 4. Plot Mean Merged Tree Height vs. k
    height_filename_base = os.path.join(output_dir, f"{dataset_name}_height_vs_k_agg_seeds.svg")
    plot_metric_vs_k(
        agg_df,
        metric_mean_col='Height_mean',
        metric_std_col='Height_std',
        y_label="Mean Merged Tree Height",
        title=f"{dataset_name.capitalize()}: Mean Merged Tree Height vs. k",
        output_filename_base=height_filename_base,
        use_log_scale=False # Linear scale only
    )

    print("\nVisualization complete.")


if __name__ == "__main__":
    # Usage Example: python visualize_benchmarks.py -d banknote
    parser = argparse.ArgumentParser(description="Visualize compile-rf benchmark results, inferring paths.")
    parser.add_argument('-d', '--dataset', type=str, required=True,
                        help='Name of the dataset (e.g., magic, banknote). Used to infer CSV path.')

    args = parser.parse_args()

    # Infer paths based on dataset name
    dataset_name = args.dataset
    base_output_dir = "results" # Base directory for results
    csv_filename = f"benchmark_results_{dataset_name}_all_seeds.csv"
    # Assume CSV is directly in the base_output_dir
    csv_path = os.path.join(base_output_dir, csv_filename)

    print(f"Dataset: {dataset_name}")
    print(f"Inferred CSV Path: {csv_path}")
    print(f"Base Output Directory: {base_output_dir}")

    # Call the visualization function with inferred/fixed paths
    visualize_results(csv_path, dataset_name, base_output_dir)
